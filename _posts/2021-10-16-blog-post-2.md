---
layout: post
title: IMDB Web Scraper
---

In this blog post we will create a web scraper for finding shared actors on IMDB. The specific code and data is hosted in this [repo](https://github.com/renzotw/IMDB-Scraper).

# §1. Preliminaries

Throuhgout this exercise we will use `Scrapy`, which is an open-source webcrawling framework for Python. Scrapy has many utilities for web scraping which we will gloss over in this blog post and implement in our own spider. Let's start by going over some of the preliminary steps to launch our Scrapy project.

In order to install `Scrapy` onto our system, follow this [link](https://docs.scrapy.org/en/latest/intro/install.html#intro-install). After `Scrapy` is installed in our system, we will start our first project by running the following command in terminal:


```python
scrapy startproject IMDB-Scraper
```

This will create a scraper directory with many files that we need to create a spider.

# §2. Creating a spider

We will now create a spider which will crawl the web and parse the exact data we desire. In particular, this spider will crawl through IMDB web pages and will have specific implementations to gather relevant actor and movie/tv show data. The baisc structure of this spider is as follws:

 - Start on IMDB page of a movie or show
 - Move to the *cast & crew* page
 - Iterate through all cast members
 - For each cast member extract all of the movies/tv shows they have worked on and return the data


## 2a. Set up

To set up our spider we type the initial code to give our spider a name and give it a starting point (this is the url where the spider will start scraping from).


```python
import scrapy
class ImdbSpider(scrapy.Spider):
    
    # Name of spider
    name = 'imdb_spider'

    # Starting point: Skyfall imdb url
    start_urls = ['https://www.imdb.com/title/tt1074638/']
```

## 2b. parse()

Now we will implement several parse methods. The very first method starts on the home page of a movie's imdb page and then navigates to the *cast & crew* page. We use the `.css()` method to extract data from the web page's html scource code. For this particular method, the *cast & crew* page is a list item so we find it with `li.ipc-inline-list__item a`. Then we update our current url with the new attribute.


```python
def parse(self, response):
        """
        This parse method starts on the home page of a movie's imdb page
        and then navigates to the cast and crew page and runs the parse_full_credits method
        """

        # Find the cast and crew page
        next_page = response.css("li.ipc-inline-list__item a")[2].attrib["href"]

        # If the cast and crew page exists, update the url, and move to it
        if next_page:
            next_page = response.urljoin(next_page) # Update url
            yield scrapy.Request(next_page, callback = self.parse_full_credits) # Move to page and run parse_full_credits
```

Upon moving to the page the spider calls on the next parse method with `yield`.

## 2c. parse_full_credits()

This parse method starts on the *cast & crew* page and yields a `scrapy.Request` for every actor listed on the page. This method specifically parses through cast members so it will exclude any crew members. The cast members are listed in a table so we find it with `table.cast_list td:not([class]) a`. We then iterate through this table to go to each actor's page.


```python
def parse_full_credits(self, response):
        """
        This parse method starts on the cast and crew page and yields a scrapy.Request 
        for every actor listed on the page. Only includes cast members.
        """

        # Iterate through table of actors
        for i in range(len(response.css("table.cast_list td:not([class]) a"))):
            cast_page = response.css("table.cast_list td:not([class]) a")[i].attrib["href"] # Get cast member id
            cast_page = response.url.rsplit("/", 4)[0] + cast_page # Update url for each cast member
            yield scrapy.Request(cast_page, callback = self.parse_actor_page) # Move to cast member page and run parse_actor_page
```

For each actor this method will call on the next `parse_actor_page()` method to extract their movie/TV show data.

## 2d. parse_actor_page()

This last parse method starts on the page of an actor and extracts all of the projects (movies/TV shows) that the actor has worked on. Then it yields a dictionary of the actor's name and the specific project title. 


```python
def parse_actor_page(self, response):
        """ 
        This parse method starts on the page of an actor and extracts all of the projects 
        that the actor has worked on. Then it yields a dictionary of the actor and the project title.
        """
        
        # Iterate through all of the projects
        for project in response.css("div.filmo-category-section")[0].css("b a::text"):
            actor_name = response.css("span.itemprop::text").get() # Get actor name
            movie_or_TV_name = project.get() # Get project title

            # Yield results in a dictionary
            yield {
                "actor" : actor_name,
                "movie_or_TV_name" : movie_or_TV_name
            }
```

# §3. Scraping the Data

We now have a functional spider that scrapes an imdb page for all of its actors and the projects that they have worked on. In order to see how many actors have worked on other projects together we will use the spider to collect all of the data and analyze it. We run the following command in terminal to implement the spider and save the data in a csv file called `results.csv`. This will cakll on all of the parse methods we wrote above and scrape the data!


```python
scrapy crawl imdb_spider -o results.csv
```

# §4. Data Analysis

The scraped data now exists in our scraper directory as `results.csv`. Let's open it and explore the data.


```python
import pandas as pd
df = pd.read_csv("results copy.csv")
```


```python
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>actor</th>
      <th>movie_or_TV_name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Daniel Craig</td>
      <td>Knives Out 3</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Daniel Craig</td>
      <td>Purity</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Daniel Craig</td>
      <td>The Creed of Violence</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Daniel Craig</td>
      <td>Knives Out 2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Daniel Craig</td>
      <td>No Time to Die</td>
    </tr>
  </tbody>
</table>
</div>



As we can see the data has two columns `actor` and `movie_or_TV_name` as we specified in our spider. The first few rows show Daniel Craig and the movies/TV shows he is featured in. We are interested in understanding what other shows share the same actors as the ones in Skyfall so we can manipulate this dataframe to produce the desired results. We will create a new sorted dataframe that sorts the csv by each movie with a number of how many times it appears in our scraped data. This is exactly how many actors in Skyfall are also in other projects.


```python
# Sort dataframe 
sorted_df = df["movie_or_TV_name"].value_counts().to_frame()
```


```python
sorted_df.head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>actors</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Skyfall</th>
      <td>159</td>
    </tr>
    <tr>
      <th>EastEnders</th>
      <td>38</td>
    </tr>
    <tr>
      <th>Holby City</th>
      <td>32</td>
    </tr>
    <tr>
      <th>Jack Ryan: Shadow Recruit</th>
      <td>29</td>
    </tr>
    <tr>
      <th>Doctors</th>
      <td>26</td>
    </tr>
    <tr>
      <th>Silent Witness</th>
      <td>25</td>
    </tr>
    <tr>
      <th>Spectre</th>
      <td>24</td>
    </tr>
    <tr>
      <th>Casualty</th>
      <td>23</td>
    </tr>
    <tr>
      <th>About Time</th>
      <td>21</td>
    </tr>
    <tr>
      <th>New Tricks</th>
      <td>21</td>
    </tr>
  </tbody>
</table>
</div>



We can see that Skyfall contains all of the actors we scraped with our spider. The next project with the most shared actors is the British TV show [EastEnders](https://www.imdb.com/title/tt0088512/). This makes sense since James Bond stars many British actors. The second project with the most shared actors is similarly a British Drama called [Holby City](https://www.imdb.com/title/tt0184122/). One unexpected result is that the next James Bond movie with the most shared actors is [Spectre](https://www.imdb.com/title/tt2379713/) withg 24 shared actors.

# §5. Conclusion

In this blog post we used `Scrapy` to create a spider that scrapes IMDB pages for the actors and all of the projects they have worked on. In particular we learned how to create parse methods that can navigate pages, call on other parse methods, and write and save data. This is a very useful tool to have when looking looking for data on the web!
